{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb3b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19648b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=300, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         1ayer 1\n",
    "        t = self.conv1(x)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "#         layer 2\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "#         layer 3\n",
    "        t = t.reshape(-1, 300)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "#         layer 4\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "#         layer 5\n",
    "        t = self.out(t)\n",
    "    \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9111d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(pred, labels):\n",
    "    return pred.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4902e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "network = Network()\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "                                        train=False, \n",
    "                                        download=False, \n",
    "                                        transform=torchvision.transforms.ToTensor())\n",
    "loader = DataLoader(trainset, batch_size=batch_size)\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b92b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = f'batch_size {batch_size} lr {lr}'\n",
    "tb = SummaryWriter(comment=comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294f3ac",
   "metadata": {},
   "source": [
    "### 多轮超参数组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573dcf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0df3898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [10, 100], 'lr': [0.01, 0.001]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同超参数组合，利用tensorboard方便调参\n",
    "param_dict = dict(\n",
    "    batch_size = [10, 100],\n",
    "    lr = [0.01, 0.001]\n",
    ")\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b2503f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 100], [0.01, 0.001]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list = [v for v in param_dict.values()]\n",
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d7a77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: total_correct:1000， total_loss: 23060.205283164978\n",
      "epoch 1: total_correct:1000， total_loss: 23060.205283164978\n",
      "epoch 2: total_correct:1000， total_loss: 23060.205283164978\n",
      "epoch 0: total_correct:1000， total_loss: 23053.6079788208\n",
      "epoch 1: total_correct:1000， total_loss: 23053.6079788208\n",
      "epoch 2: total_correct:1000， total_loss: 23053.6079788208\n",
      "epoch 0: total_correct:1000， total_loss: 23051.1855840683\n",
      "epoch 1: total_correct:1000， total_loss: 23051.1855840683\n",
      "epoch 2: total_correct:1000， total_loss: 23051.1855840683\n",
      "epoch 0: total_correct:1000， total_loss: 23039.924359321594\n",
      "epoch 1: total_correct:1000， total_loss: 23039.924359321594\n",
      "epoch 2: total_correct:1000， total_loss: 23039.924359321594\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for batch_size, lr in product(*param_list):\n",
    "    network = Network()\n",
    "    \n",
    "    loader = DataLoader(trainset, batch_size=batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    comment = f'batch_size {batch_size} lr {lr}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "\n",
    "#     comment = f'batch_size:{batch_size} lr={lr}'\n",
    "#     tb = SummaryWriter(log_dir=\".\\\\runs\\\\2024-4-15C\", comment=comment)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_correct = 0\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        #     计算梯度之前，由于梯度会累积，要清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "    #         使不同batch_size的loss可比较\n",
    "            total_loss += loss.item() * batch_size\n",
    "\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        # add info to tb\n",
    "        tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        tb.add_scalar(\"Number_Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct / len(trainset), epoch)\n",
    "\n",
    "    #     tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "    #     tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "    #     tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)\n",
    "\n",
    "    #   del hard code\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "\n",
    "        print(f'epoch {epoch}: total_correct:{total_correct}， total_loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a623b0",
   "metadata": {},
   "source": [
    "### 封装类，优化代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3803f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager:\n",
    "    def __init__(self):\n",
    "#         self.epoch_num = 0 # 总数\n",
    "        self.epoch_count = 0 # 当前epoch\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_correct_num = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None        \n",
    "        self.tb = None\n",
    "    \n",
    "    def begin_run(self, run, network, loader):\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "        self.run_start_time = time.time() \n",
    "        \n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        #     comment：tensorboard文件目录后缀，用于区分不同超参数组合\n",
    "        self.tb = SummaryWriter(comment=f\"-{run}\")\n",
    "        \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "        \n",
    "    def begin_epoch(self):\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_correct_num = 0\n",
    "        \n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "        \n",
    "        acc = self.epoch_correct_num / len(self.loader.dataset)\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        \n",
    "        self.tb.add_scalar(\"Accuracy\", acc, self.epoch_count)\n",
    "        self.tb.add_scalar(\"Loss\", loss, self.epoch_count)\n",
    "        \n",
    "        for name, weight in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, weight, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', weight.grad, self.epoch_count)\n",
    "            \n",
    "        result = OrderedDict()\n",
    "        result['run'] = self.run_count\n",
    "        result['epoch'] = self.epoch_count\n",
    "        result['acc'] = acc\n",
    "        result['loss'] = loss\n",
    "        result['run_duration'] = run_duration\n",
    "        result['epoch_duration'] = epoch_duration\n",
    "        for k, v in self.run_params._asdict().items():\n",
    "            result[k] = v\n",
    "        \n",
    "        self.run_data.append(result)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        \n",
    "        # notebook使用\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        \n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "    \n",
    "    def track_correct(self, preds, labels):\n",
    "        self.epoch_correct_num += self._get_num_correct(preds, labels)\n",
    "    \n",
    "#     @torch.no_grad() #推理阶段使用\n",
    "    def _get_num_correct(self, pred, labels):\n",
    "        return pred.argmax(dim=1).eq(labels).sum().item()\n",
    "        \n",
    "    \n",
    "    def save(self, filename):\n",
    "#         保存为csv\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data,\n",
    "            orient='columns'\n",
    "        ).to_csv(f'{filename}.csv')\n",
    "    \n",
    "#         保存为json\n",
    "#         with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
    "#             json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40c948c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建RunBuilder，方便超参数元组获取, 最外层循环\n",
    "\n",
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2662e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('batch_size', [10, 100]), ('lr', [0.01, 0.001])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同超参数组合，利用tensorboard方便调参\n",
    "param_dict = OrderedDict(\n",
    "    batch_size = [10, 100],\n",
    "    lr = [0.01, 0.001]\n",
    ")\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c022f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "                                        train=False, \n",
    "                                        download=False, \n",
    "                                        transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d816d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>2.305632</td>\n",
       "      <td>3.949818</td>\n",
       "      <td>3.947663</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>2.305288</td>\n",
       "      <td>8.986098</td>\n",
       "      <td>4.973881</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>2.305291</td>\n",
       "      <td>13.805143</td>\n",
       "      <td>4.772722</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>2.070462</td>\n",
       "      <td>4.154894</td>\n",
       "      <td>4.152935</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>1.813963</td>\n",
       "      <td>8.785284</td>\n",
       "      <td>4.549803</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>1.658225</td>\n",
       "      <td>13.372157</td>\n",
       "      <td>4.500383</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>2.290103</td>\n",
       "      <td>2.360542</td>\n",
       "      <td>2.358541</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>2.020378</td>\n",
       "      <td>4.907425</td>\n",
       "      <td>2.470867</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>1.891319</td>\n",
       "      <td>7.449193</td>\n",
       "      <td>2.465861</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1657</td>\n",
       "      <td>2.186775</td>\n",
       "      <td>2.511396</td>\n",
       "      <td>2.508522</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>1.962341</td>\n",
       "      <td>5.117784</td>\n",
       "      <td>2.530179</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>1.853072</td>\n",
       "      <td>7.623313</td>\n",
       "      <td>2.416890</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch     acc      loss  run_duration  epoch_duration  batch_size  \\\n",
       "0     1      1  0.0957  2.305632      3.949818        3.947663          10   \n",
       "1     1      2  0.0977  2.305288      8.986098        4.973881          10   \n",
       "2     1      3  0.0977  2.305291     13.805143        4.772722          10   \n",
       "3     2      1  0.2208  2.070462      4.154894        4.152935          10   \n",
       "4     2      2  0.3308  1.813963      8.785284        4.549803          10   \n",
       "5     2      3  0.3850  1.658225     13.372157        4.500383          10   \n",
       "6     3      1  0.1187  2.290103      2.360542        2.358541         100   \n",
       "7     3      2  0.2377  2.020378      4.907425        2.470867         100   \n",
       "8     3      3  0.2913  1.891319      7.449193        2.465861         100   \n",
       "9     4      1  0.1657  2.186775      2.511396        2.508522         100   \n",
       "10    4      2  0.2781  1.962341      5.117784        2.530179         100   \n",
       "11    4      3  0.3173  1.853072      7.623313        2.416890         100   \n",
       "\n",
       "       lr  \n",
       "0   0.010  \n",
       "1   0.010  \n",
       "2   0.010  \n",
       "3   0.001  \n",
       "4   0.001  \n",
       "5   0.001  \n",
       "6   0.010  \n",
       "7   0.010  \n",
       "8   0.010  \n",
       "9   0.001  \n",
       "10  0.001  \n",
       "11  0.001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3 # 也可加入 param_dict\n",
    "\n",
    "r = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(param_dict):\n",
    "    network = Network() # network 权重随机初始化，在测试不同超参数时不符合控制变量法\n",
    "    loader = DataLoader(trainset, batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    r.begin_run(run, network, loader)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        r.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        #     计算梯度之前，由于梯度会累积，要清零\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            r.track_loss(loss)\n",
    "            r.track_correct(preds, labels)\n",
    "\n",
    "        r.end_epoch()\n",
    "#         print(f'epoch {epoch}: total_correct:{total_correct}， total_loss: {total_loss}')\n",
    "    \n",
    "    r.end_run()\n",
    "\n",
    "# 保存文件\n",
    "r.save('first_trial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00552aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>1.658225</td>\n",
       "      <td>13.372157</td>\n",
       "      <td>4.500383</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>1.813963</td>\n",
       "      <td>8.785284</td>\n",
       "      <td>4.549803</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3173</td>\n",
       "      <td>1.853072</td>\n",
       "      <td>7.623313</td>\n",
       "      <td>2.416890</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2913</td>\n",
       "      <td>1.891319</td>\n",
       "      <td>7.449193</td>\n",
       "      <td>2.465861</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2781</td>\n",
       "      <td>1.962341</td>\n",
       "      <td>5.117784</td>\n",
       "      <td>2.530179</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>2.020378</td>\n",
       "      <td>4.907425</td>\n",
       "      <td>2.470867</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>2.070462</td>\n",
       "      <td>4.154894</td>\n",
       "      <td>4.152935</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1657</td>\n",
       "      <td>2.186775</td>\n",
       "      <td>2.511396</td>\n",
       "      <td>2.508522</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1187</td>\n",
       "      <td>2.290103</td>\n",
       "      <td>2.360542</td>\n",
       "      <td>2.358541</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>2.305288</td>\n",
       "      <td>8.986098</td>\n",
       "      <td>4.973881</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>2.305291</td>\n",
       "      <td>13.805143</td>\n",
       "      <td>4.772722</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>2.305632</td>\n",
       "      <td>3.949818</td>\n",
       "      <td>3.947663</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch     acc      loss  run_duration  epoch_duration  batch_size  \\\n",
       "5     2      3  0.3850  1.658225     13.372157        4.500383          10   \n",
       "4     2      2  0.3308  1.813963      8.785284        4.549803          10   \n",
       "11    4      3  0.3173  1.853072      7.623313        2.416890         100   \n",
       "8     3      3  0.2913  1.891319      7.449193        2.465861         100   \n",
       "10    4      2  0.2781  1.962341      5.117784        2.530179         100   \n",
       "7     3      2  0.2377  2.020378      4.907425        2.470867         100   \n",
       "3     2      1  0.2208  2.070462      4.154894        4.152935          10   \n",
       "9     4      1  0.1657  2.186775      2.511396        2.508522         100   \n",
       "6     3      1  0.1187  2.290103      2.360542        2.358541         100   \n",
       "1     1      2  0.0977  2.305288      8.986098        4.973881          10   \n",
       "2     1      3  0.0977  2.305291     13.805143        4.772722          10   \n",
       "0     1      1  0.0957  2.305632      3.949818        3.947663          10   \n",
       "\n",
       "       lr  \n",
       "5   0.001  \n",
       "4   0.001  \n",
       "11  0.001  \n",
       "8   0.010  \n",
       "10  0.001  \n",
       "7   0.010  \n",
       "3   0.001  \n",
       "9   0.001  \n",
       "6   0.010  \n",
       "1   0.010  \n",
       "2   0.010  \n",
       "0   0.010  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(r.run_data).sort_values('acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414359c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(batch_size=10, lr=0.01),\n",
       " Run(batch_size=10, lr=0.001),\n",
       " Run(batch_size=100, lr=0.01),\n",
       " Run(batch_size=100, lr=0.001)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上图中可以发现最佳组合：Run(batch_size=10, lr=0.001)\n",
    "run = RunBuilder.get_runs(param_dict)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512f459",
   "metadata": {},
   "source": [
    "### RunBuilder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31e5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = dict(\n",
    "    batch_size=[10, 100],\n",
    "    lr=[0.1, 0.01],\n",
    "    shuffle=[True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae80e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 100], [0.1, 0.01], [True, False]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list = [v for v in param_dict.values()]\n",
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e25cfe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10, 0.1, True\n",
      "10, 0.1, False\n",
      "10, 0.01, True\n",
      "10, 0.01, False\n",
      "100, 0.1, True\n",
      "100, 0.1, False\n",
      "100, 0.01, True\n",
      "100, 0.01, False\n"
     ]
    }
   ],
   "source": [
    "for batch_size, lr, shuffle in product(*param_list):\n",
    "    print(f'{batch_size}, {lr}, {shuffle}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a277bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = OrderedDict(\n",
    "    batch_size=[10, 100],\n",
    "    lr=[0.1, 0.01],\n",
    "    shuffle=[True, False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66b0d668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['batch_size', 'lr', 'shuffle'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建RunBuilder，方便超参数元组获取\n",
    "\n",
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            print(v)\n",
    "            print(\"===\")\n",
    "            print(*v)\n",
    "            print(\"=====\")\n",
    "            runs.append(Run(*v))\n",
    "        \n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbef7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.1, True)\n",
      "===\n",
      "10 0.1 True\n",
      "=====\n",
      "(10, 0.1, False)\n",
      "===\n",
      "10 0.1 False\n",
      "=====\n",
      "(10, 0.01, True)\n",
      "===\n",
      "10 0.01 True\n",
      "=====\n",
      "(10, 0.01, False)\n",
      "===\n",
      "10 0.01 False\n",
      "=====\n",
      "(100, 0.1, True)\n",
      "===\n",
      "100 0.1 True\n",
      "=====\n",
      "(100, 0.1, False)\n",
      "===\n",
      "100 0.1 False\n",
      "=====\n",
      "(100, 0.01, True)\n",
      "===\n",
      "100 0.01 True\n",
      "=====\n",
      "(100, 0.01, False)\n",
      "===\n",
      "100 0.01 False\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "runs = RunBuilder.get_runs(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef0e6810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 10, 'lr': 0.1, 'shuffle': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[0]._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37ff5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(batch_size=10, lr=0.1, shuffle=True),\n",
       " Run(batch_size=10, lr=0.1, shuffle=False),\n",
       " Run(batch_size=10, lr=0.01, shuffle=True),\n",
       " Run(batch_size=10, lr=0.01, shuffle=False),\n",
       " Run(batch_size=100, lr=0.1, shuffle=True),\n",
       " Run(batch_size=100, lr=0.1, shuffle=False),\n",
       " Run(batch_size=100, lr=0.01, shuffle=True),\n",
       " Run(batch_size=100, lr=0.01, shuffle=False)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3e19169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.1\n",
      "True\n",
      "10\n",
      "0.1\n",
      "False\n",
      "10\n",
      "0.01\n",
      "True\n",
      "10\n",
      "0.01\n",
      "False\n",
      "100\n",
      "0.1\n",
      "True\n",
      "100\n",
      "0.1\n",
      "False\n",
      "100\n",
      "0.01\n",
      "True\n",
      "100\n",
      "0.01\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run.batch_size)\n",
    "    print(run.lr)\n",
    "    print(run.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bff42",
   "metadata": {},
   "source": [
    "### Normalize(Standardize 更具体的数据缩放变换)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc6c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理阶段，读取trainset，计算mean，std，之后训练时重新加载trainset，这里给出假设值，测试重新加载\n",
    "mean = 0.\n",
    "std = 1.\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "                                        train=False, \n",
    "                                        download=False, \n",
    "                                        transform=torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize(mean, std)\n",
    "                                        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46199d5",
   "metadata": {},
   "source": [
    "### Sequential Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc1e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = OrderedDict([\n",
    "    ('flat', nn.Flatten(start_dim=1)),\n",
    "    ('hidden', nn.Linear(in_features=784, out_features=392)),\n",
    "    ('output', nn.Linear(in_features=392, out_features=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc8459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2 = nn.Sequential(layers)\n",
    "network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092675df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=300, out_features=120, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最初定义的Network类，可使用nn.Sequential构建等价的网络\n",
    "\n",
    "network_seq1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=300, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")\n",
    "network_seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0eefc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (output): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用OrderedDict 创建，指定每层的名字\n",
    "\n",
    "seq2_layers = OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('maxPool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('maxPool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('flatten', nn.Flatten(start_dim=1)),\n",
    "    ('lin1', nn.Linear(in_features=300, out_features=120)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('lin2', nn.Linear(in_features=120, out_features=60)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('output', nn.Linear(in_features=60, out_features=10))\n",
    "    \n",
    "])\n",
    "\n",
    "network_seq2 = nn.Sequential(seq2_layers)\n",
    "network_seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05c568e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (batchNorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (batchNorm2): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (output): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加 Batch_norm\n",
    "\n",
    "seq_batch_layers = OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('maxPool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('batchNorm1', nn.BatchNorm2d(6)),\n",
    "    \n",
    "    ('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('maxPool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('flatten', nn.Flatten(start_dim=1)),\n",
    "    ('lin1', nn.Linear(in_features=300, out_features=120)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    \n",
    "    ('batchNorm2', nn.BatchNorm1d(120)),\n",
    "    \n",
    "    ('lin2', nn.Linear(in_features=120, out_features=60)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('output', nn.Linear(in_features=60, out_features=10))\n",
    "    \n",
    "])\n",
    "\n",
    "network_seq3 = nn.Sequential(seq_batch_layers)\n",
    "network_seq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7fbb5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network1': Sequential(\n",
       "   (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (relu1): ReLU()\n",
       "   (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (relu2): ReLU()\n",
       "   (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
       "   (relu3): ReLU()\n",
       "   (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
       "   (relu4): ReLU()\n",
       "   (output): Linear(in_features=60, out_features=10, bias=True)\n",
       " ),\n",
       " 'network2': Sequential(\n",
       "   (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (relu1): ReLU()\n",
       "   (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (batchNorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (relu2): ReLU()\n",
       "   (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
       "   (relu3): ReLU()\n",
       "   (batchNorm2): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
       "   (relu4): ReLU()\n",
       "   (output): Linear(in_features=60, out_features=10, bias=True)\n",
       " )}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_dict = {\n",
    "    'network1': network_seq2,\n",
    "    'network2': network_seq3\n",
    "}\n",
    "net_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbafe47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['network1', 'network2']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361242ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =  tensor([[[[25.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.]]],\n",
      "\n",
      "\n",
      "        [[[ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.,  1.]]]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(size=(2, 2, 3, 4))\n",
    "data[0][0][0][0] = 25\n",
    "print(\"data = \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739729f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((data[0][0], data[1][0]), dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a76d42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(23.)\n"
     ]
    }
   ],
   "source": [
    "x_mean = torch.Tensor.mean(x)\n",
    "x_var = torch.Tensor.var(x, False)\n",
    "print(x_mean)\n",
    "print(x_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a726ca",
   "metadata": {},
   "source": [
    "### batch_norm 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418c564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_normal = OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('maxPool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('maxPool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('flatten', nn.Flatten(start_dim=1)),\n",
    "    ('lin1', nn.Linear(in_features=300, out_features=120)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    ('lin2', nn.Linear(in_features=120, out_features=60)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('output', nn.Linear(in_features=60, out_features=10))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256ebba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_with_batch = OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('maxPool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('batchNorm1', nn.BatchNorm2d(6)),\n",
    "    \n",
    "    ('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('maxPool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "    \n",
    "    ('flatten', nn.Flatten(start_dim=1)),\n",
    "    ('lin1', nn.Linear(in_features=300, out_features=120)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "    \n",
    "    ('batchNorm2', nn.BatchNorm1d(120)),\n",
    "    \n",
    "    ('lin2', nn.Linear(in_features=120, out_features=60)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('output', nn.Linear(in_features=60, out_features=10))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b76d9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkFactory:\n",
    "    @staticmethod\n",
    "    def get_factory(name):\n",
    "        if name == \"network\":\n",
    "            torch.manual_seed(50)\n",
    "            return nn.Sequential(layers_normal)\n",
    "        elif name == \"network_with_batchnorm\":\n",
    "            torch.manual_seed(50)\n",
    "            return nn.Sequential(layers_with_batch)\n",
    "        else:\n",
    "            return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fe70f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('batch_size', [10]),\n",
       "             ('lr', [0.001]),\n",
       "             ('network', ['network', 'network_with_batchnorm'])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同超参数组合，利用tensorboard方便调参\n",
    "param_dict = OrderedDict(\n",
    "    batch_size = [10],\n",
    "    lr = [0.001],\n",
    "    network = ['network', 'network_with_batchnorm']\n",
    ")\n",
    "param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "181e1249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[10], [0.001], ['network', 'network_with_batchnorm']])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db925bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 0.001, 'network')\n",
      "(10, 0.001, 'network_with_batchnorm')\n"
     ]
    }
   ],
   "source": [
    "for x in product(*param_dict.values()):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eafdd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "                                        train=False, \n",
    "                                        download=False, \n",
    "                                        transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "532fb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(trainset, batch_size=len(trainset), num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d33d6eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4766), tensor(0.2512))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 等价写法\n",
    "# data = next(iter(loader))\n",
    "# data[0].mean(), data[0].std()\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "images.mean(), images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62830a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = images.mean()\n",
    "std = images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40e37184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de0270bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30720000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "#                                         train=False, \n",
    "#                                         download=False, \n",
    "#                                         transform=torchvision.transforms.ToTensor())\n",
    "# loader = DataLoader(trainset, batch_size=len(trainset), num_workers=1)\n",
    "# images, labels = next(iter(loader))\n",
    "\n",
    "# mean = images.mean()\n",
    "# std = images.std()\n",
    "\n",
    "\n",
    "\n",
    "# pixel_total = images.numel()\n",
    "\n",
    "# images, labels = next(iter(loader))\n",
    "# mean = images.sum() / pixel_total\n",
    "# powsum = (images - mean).pow(2).sum()\n",
    "\n",
    "# std = torch.sqrt(powsum / pixel_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb9abddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_normal = torchvision.datasets.CIFAR10(\"../pytorch_test/testdata\", \n",
    "                                        train=False, \n",
    "                                        download=False, \n",
    "                                        transform=torchvision.transforms.Compose([\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            torchvision.transforms.Normalize(mean, std)\n",
    "                                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2f99d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>1.825468</td>\n",
       "      <td>4.553105</td>\n",
       "      <td>4.551018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>1.555610</td>\n",
       "      <td>9.347095</td>\n",
       "      <td>4.688157</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>1.417843</td>\n",
       "      <td>14.191598</td>\n",
       "      <td>4.762349</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>1.795440</td>\n",
       "      <td>4.944481</td>\n",
       "      <td>4.942454</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4357</td>\n",
       "      <td>1.553575</td>\n",
       "      <td>10.358989</td>\n",
       "      <td>5.312581</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>1.457439</td>\n",
       "      <td>15.701468</td>\n",
       "      <td>5.232157</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch     acc      loss  run_duration  epoch_duration  batch_size  \\\n",
       "0    1      1  0.3259  1.825468      4.553105        4.551018          10   \n",
       "1    1      2  0.4309  1.555610      9.347095        4.688157          10   \n",
       "2    1      3  0.4855  1.417843     14.191598        4.762349          10   \n",
       "3    2      1  0.3414  1.795440      4.944481        4.942454          10   \n",
       "4    2      2  0.4357  1.553575     10.358989        5.312581          10   \n",
       "5    2      3  0.4785  1.457439     15.701468        5.232157          10   \n",
       "\n",
       "      lr                 network  \n",
       "0  0.001                 network  \n",
       "1  0.001                 network  \n",
       "2  0.001                 network  \n",
       "3  0.001  network_with_batchnorm  \n",
       "4  0.001  network_with_batchnorm  \n",
       "5  0.001  network_with_batchnorm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "r = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(param_dict):\n",
    "    network = NetworkFactory.get_factory(run.network)\n",
    "    loader = DataLoader(trainset_normal, batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    r.begin_run(run, network, loader)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        r.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        #     计算梯度之前，由于梯度会累积，要清零\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            r.track_loss(loss)\n",
    "            r.track_correct(preds, labels)\n",
    "\n",
    "        r.end_epoch()\n",
    "#         print(f'epoch {epoch}: total_correct:{total_correct}， total_loss: {total_loss}')\n",
    "    \n",
    "    r.end_run()\n",
    "\n",
    "# 保存文件\n",
    "r.save('batch_compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "074ff17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4855</td>\n",
       "      <td>1.417843</td>\n",
       "      <td>14.191598</td>\n",
       "      <td>4.762349</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>1.457439</td>\n",
       "      <td>15.701468</td>\n",
       "      <td>5.232157</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4357</td>\n",
       "      <td>1.553575</td>\n",
       "      <td>10.358989</td>\n",
       "      <td>5.312581</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>1.555610</td>\n",
       "      <td>9.347095</td>\n",
       "      <td>4.688157</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>1.795440</td>\n",
       "      <td>4.944481</td>\n",
       "      <td>4.942454</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network_with_batchnorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>1.825468</td>\n",
       "      <td>4.553105</td>\n",
       "      <td>4.551018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch     acc      loss  run_duration  epoch_duration  batch_size  \\\n",
       "2    1      3  0.4855  1.417843     14.191598        4.762349          10   \n",
       "5    2      3  0.4785  1.457439     15.701468        5.232157          10   \n",
       "4    2      2  0.4357  1.553575     10.358989        5.312581          10   \n",
       "1    1      2  0.4309  1.555610      9.347095        4.688157          10   \n",
       "3    2      1  0.3414  1.795440      4.944481        4.942454          10   \n",
       "0    1      1  0.3259  1.825468      4.553105        4.551018          10   \n",
       "\n",
       "      lr                 network  \n",
       "2  0.001                 network  \n",
       "5  0.001  network_with_batchnorm  \n",
       "4  0.001  network_with_batchnorm  \n",
       "1  0.001                 network  \n",
       "3  0.001  network_with_batchnorm  \n",
       "0  0.001                 network  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(r.run_data).sort_values('acc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2002dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (output): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "=========\n",
      "Sequential(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxPool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (batchNorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxPool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (lin1): Linear(in_features=300, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (batchNorm2): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lin2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (output): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "# for run in RunBuilder.get_runs(param_dict):\n",
    "#     network = NetworkFactory.get_factory(run.network)\n",
    "#     print(network)\n",
    "#     print(\"=========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49e6bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1000\n",
      "0\n",
      "10\n",
      "10000\n",
      "=========\n",
      "10\n",
      "1000\n",
      "0\n",
      "10\n",
      "10000\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "for run in RunBuilder.get_runs(param_dict):\n",
    "    print(run.batch_size)\n",
    "    loader = DataLoader(trainset_normal, batch_size=run.batch_size)\n",
    "    print(len(loader)) # 有几个batch\n",
    "    print(loader.num_workers)\n",
    "    print(loader.batch_size)\n",
    "    print(len(loader.dataset)) # 有多少数据\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e99d13b",
   "metadata": {},
   "source": [
    "### 多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e193e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiheadAttention).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_combine = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        batch, time, dimension = q.shape\n",
    "        \n",
    "        n_d = self.d_model / self.n_head\n",
    "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
    "        \n",
    "        q = q.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        k = k.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)     \n",
    "        v = v.view(batch, time, self.n_head, n_d).permute(0, 2, 1, 3)\n",
    "        \n",
    "        score = q @ k.transpose(2, 3) / math.sqrt(n_d)\n",
    "        mask = torch.tril(torch.ones(time, time, dtype=bool))\n",
    "        score = score.masked_fill(mask == 0, float(\"-inf\"))\n",
    "        score = self.softmax(score) @ v\n",
    "        \n",
    "        # 连接多个头\n",
    "        score = score.permute(0, 2, 1, 3).contiguous().view(batch, time, dimension)\n",
    "        \n",
    "        # 输入到最后的线性层\n",
    "        output = self.w_combine(score)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f586eb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1., 2, 3], [4,5,6], [7,8,9]])\n",
    "ts.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b56fbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False],\n",
       "        [ True,  True, False],\n",
       "        [ True,  True,  True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(3, 3, dtype=bool))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca00b67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf],\n",
       "        [4., 5., -inf],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.masked_fill(mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a80e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed63a014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.Tensor(2, 3, 4, 5)\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fbf2919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4, 5])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd43356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.transpose(0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fb160b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 4, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.transpose(0, 3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc24e2",
   "metadata": {},
   "source": [
    "# Transformer 学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2d983",
   "metadata": {},
   "source": [
    "# 嵌入表示层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7631667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始序列不具有token之间的相对位置信息\n",
    "# 最初单词（token）表示和位置编码相加，利用三角函数的性质加入单词之间的距离信息\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, dmodel, max_seq_len=80):\n",
    "        super().__init__()\n",
    "        self.dmodel = dmodel\n",
    "        \n",
    "        # 根据 pos 和 i 创建一个常量 PE 矩阵\n",
    "        pe = torch.zeros(max_seq_len, dmodel)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, dmodel, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / dmodel)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * (i + 1) / dmodel)))\n",
    "        \n",
    "#         在最外层（第0维度）增加一个维度，以适应batch\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x * math.sqrt(self.dmodel)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:, :seq_len], requires_grad=False).cuda()\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36a30b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1., 2.], [4,5], [7,8]])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acca24b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d31dbcc",
   "metadata": {},
   "source": [
    "# 多头注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9fbe993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        # 掩盖掉那些为了填补长度增加的单元，使其通过 softmax 计算后为 0\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "            scores = F.softmax(scores, dim=-1)\n",
    "        if dropout is not None:\n",
    "            scores = dropout(scores)\n",
    "            output = torch.matmul(scores, v)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        bs = q.size(0)\n",
    "        # 进行线性操作划分为成 h 个头\n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        # 矩阵转置\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        # 计算 attention\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        # 连接多个头并输入到最后的线性层\n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        output = self.out(concat)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693adf96",
   "metadata": {},
   "source": [
    "# 位置感知前馈层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b7c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dmodel, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(dmodel, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, dmodel)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear1(x)))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f893bc",
   "metadata": {},
   "source": [
    "# 残差连接与层归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d410b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormLayer(nn.Module):\n",
    "    def __init__(self, dmodel, eps=1e-6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size = dmodel\n",
    "        # 层归一化包含两个可学习的参数\n",
    "        self.alpha = nn.Parameter(torch.ones(dmodel))\n",
    "        self.bias = nn.Parameter(torch.zeros(dmodel))\n",
    "        \n",
    "        self.eps = eps\n",
    "    \n",
    "    # x 是残差连接后的tensor\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18d5c1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1., 2.], [4,5], [7,8]])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65d123b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071],\n",
       "        [0.7071],\n",
       "        [0.7071]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.std(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920b986",
   "metadata": {},
   "source": [
    "# Transformer完整架构代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08c0bbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2,mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        \n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return self.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52813bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.norm_3 = Norm(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        self.dropout_3 = nn.Dropout(dropout)\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model, dropout=dropout)\n",
    "        self.ff = FeedForward(d_model, dropout=dropout)\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn_1(x2, x2, x2, trg_mask))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.attn_2(x2, e_outputs, e_outputs, src_mask))\n",
    "        x2 = self.norm_3(x)\n",
    "        x = x + self.dropout_3(self.ff(x2))\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.embed = Embedder(vocab_size, d_model)\n",
    "        self.pe = PositionalEncoder(d_model, dropout=dropout)\n",
    "        self.layers = get_clones(DecoderLayer(d_model, heads, dropout), N)\n",
    "        self.norm = Norm(d_model)\n",
    "    \n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d19dff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, d_model, N, heads, dropout)\n",
    "        self.decoder = Decoder(trg_vocab, d_model, N, heads, dropout)\n",
    "        self.out = nn.Linear(d_model, trg_vocab)\n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3804e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3ab20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bbb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc6763c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2ae7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc2e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec434fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
